{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "For the exercises throughout the rest of this lesson, we'll use a relatively small labeled dataset to try out feature extraction and training a classifier. Before we get on to extracting HOG features and training a classifier, let's explore the dataset a bit. This dataset is a subset of the data you'll be starting with for the project.\n",
    "\n",
    "There's no need to download anything at this point, but if you want to, you can download this subset of images for [vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles_smallset.zip) and [non-vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles_smallset.zip), or if you prefer you can directly grab the larger project dataset for [vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip) and [non-vehicles](https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip).\n",
    "\n",
    "These datasets are comprised of images taken from the [GTI vehicle image database](http://www.gti.ssr.upm.es/data/Vehicle_database.html), the [KITTI vision benchmark suite](http://www.cvlibs.net/datasets/kitti/), and examples extracted from the project video itself. In this exercise, you can explore the data to see what you're working with.\n",
    "\n",
    "You are also welcome and encouraged to explore the recently released Udacity labeled dataset. Each of the [Udacity datasets](https://github.com/udacity/self-driving-car/tree/master/annotations) comes with a `labels.csv` file that gives bounding box corners for each object labeled.\n",
    "\n",
    "![car-not-car-examples.jpg](./img/car-not-car-examples.jpg)\n",
    "\n",
    "Here, I've provided you with the code to extract the car/not-car image filenames into two lists. Write a function that takes in these two lists and returns a dictionary with the keys \"n_cars\", \"n_notcars\", \"image_shape\", and \"data_type\", like this:\n",
    "```python\n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    # Read in a test image, either car or notcar\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your function returned a count of 1196  cars and 1125  non-cars\n",
      "of size:  (64, 64, 3)  and data type: uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Example Not-car Image')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "#from skimage.feature import hog\n",
    "#from skimage import color, exposure\n",
    "# images are divided up into vehicles and non-vehicles\n",
    "\n",
    "images = glob.glob('./*/*/*.jpeg')\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "for image in images:\n",
    "    if 'image' in image or 'extra' in image:\n",
    "        notcars.append(image)\n",
    "    else:\n",
    "        cars.append(image)\n",
    "        \n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "    \n",
    "\n",
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('Your function returned a count of', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])\n",
    "# Just for fun choose random car / not-car indices and plot example images   \n",
    "car_ind = np.random.randint(0, len(cars))\n",
    "notcar_ind = np.random.randint(0, len(notcars))\n",
    "    \n",
    "# Read in car / not-car images\n",
    "car_image = mpimg.imread(cars[car_ind])\n",
    "notcar_image = mpimg.imread(notcars[notcar_ind])\n",
    "\n",
    "\n",
    "# Plot the examples\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(car_image)\n",
    "plt.title('Example Car Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(notcar_image)\n",
    "plt.title('Example Not-car Image')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
